{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b24cc8d",
   "metadata": {},
   "source": [
    "# Metody Programowania Równoległego\n",
    "## Temat: Map Reduce\n",
    "\n",
    "**Wykonał: Paweł Kruczkiewicz**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b148c20a",
   "metadata": {},
   "source": [
    "## Algorytm sekwencyjny\n",
    "### Implementacja\n",
    "\n",
    "W celu efektywnej implementacji użyto biblioteki `smart_open` stworzonej specjalnie do przetwarzania danych z EC2. Użyty kod:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "\"\"\"word_count_whole_file.py\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from smart_open import open\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    for filename in [\"s3://mpr-balis/gutenberg-1G.txt\",\"s3://mpr-balis/gutenberg-5G.txt\",\"s3://mpr-balis/gutenberg-10G.txt\"]:\n",
    "        for i in range(4):\n",
    "            word_count = {}\n",
    "            time1 = time.time()\n",
    "            \n",
    "            for line in open('s3://mpr-balis/gutenberg-1G.txt', encoding=\"latin-1\"):\n",
    "                words = line.strip().split()\n",
    "                for word in words:\n",
    "                    if word not in word_count:\n",
    "                        word_count[word] = 0\n",
    "                    word_count[word] += 1\n",
    "                \n",
    "            time_elapsed = round(time.time() - time1, 2)\n",
    "            print(f\"{i+1}\\t{filename}\\t{time_elapsed}[s]\")\n",
    "```\n",
    "\n",
    "\n",
    "### Konfiguracja\n",
    "\n",
    "Powyższy kod dla 3 typów wykonano na maszynie EC2 o typie instancji `m4.large`.\n",
    "\n",
    "![ec2](ec2_instance_type.png)\n",
    "\n",
    "\n",
    "Wyniki przedstawiono w dalszej części sprawozdania.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "961ed1b3",
   "metadata": {},
   "source": [
    "## Algorytm z użyciem paradygmatu *Map Reduce*\n",
    "\n",
    "\n",
    "### Implementacja\n",
    "\n",
    "Użyto standardowej implementacji  `mapper.py`\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "\"\"\"mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split()\n",
    "    # increase counters\n",
    "    for word in words:\n",
    "        # write the results to STDOUT (standard output);\n",
    "        # what we output here will be the input for the\n",
    "        # Reduce step, i.e. the input for reducer.py\n",
    "        #\n",
    "        # tab-delimited; the trivial word count is 1\n",
    "        print '%s\\t%s' % (word, 1)\n",
    "```\n",
    "\n",
    "oraz `reducer.py`\n",
    "\n",
    "```python\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\"\"\"reducer.py\"\"\"\n",
    "\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "# input comes from STDIN\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "\n",
    "    # parse the input we got from mapper.py\n",
    "    word, count = line.split('\\t', 1)\n",
    "\n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    "\n",
    "    # this IF-switch only works because Hadoop sorts map output\n",
    "    # by key (here: word) before it is passed to the reducer\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            # write result to STDOUT\n",
    "            print '%s\\t%s' % (current_word, current_count)\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "# do not forget to output the last word if needed!\n",
    "if current_word == word:\n",
    "    print '%s\\t%s' % (current_word, current_count)\n",
    "    \n",
    "```\n",
    "\n",
    "### Konfiguracja\n",
    "\n",
    "Powyższy kod zastosowano w paradygmacie `Map Reduce` na maszynie `EMR` w `Amazon Cloud Service`. Dokładne konfiguracje zostały opisane niżej.\n",
    "\n",
    "Aby uruchomić i sprawdzić powyższy kod *dla każdego klastra*:\n",
    "  1. Przesłano plik `gutenberg-1g.txt` za pomocą `scp`.\n",
    "  2. Rozpakowano go i wrzucono na hadoopa za pomocą komend `hdfs dfs -touchz` oraz `hdfs dfs -appendFileTo`.\n",
    "  3. Stworzono pliki `mapper.py` oraz `reducer.py` z treścią jak wyżej.\n",
    "  4. Zamieszczono i użyto skryptu `script.sh` przechwytującego `time` do pliku `time.txt`. \n",
    "  5. Przeanalizowano plik `time.txt` i dodano odpowiednie linie do pliku `result.csv` zawierającego wyniki eksperymentu w formie pliku `csv`.\n",
    "\n",
    "Plik `script.sh`\n",
    "```bash\n",
    "for size in 1 5 10\n",
    "do\n",
    "        input=\"books-input/${size}g.txt\"\n",
    "        for test_case_num in {1..3}\n",
    "        do\n",
    "                { time hadoop jar /usr/lib/hadoop/hadoop-streaming.jar \\\n",
    "                                -files mapper.py,reducer.py\\\n",
    "                                 -mapper mapper.py -reducer reducer.py \\\n",
    "                                -input ${input} -output books-output ; } 2>>time.txt\n",
    "                hdfs dfs -rm -r books-output\n",
    "        done\n",
    "done\n",
    "```\n",
    "\n",
    "Wielkość konfiguracji to użyte sumarycznie max 12 core'ów.\n",
    "\n",
    "#### Pierwsza konfiguracja\n",
    "\n",
    "Pierwsza konfiguracja to **3 x 4 core'y** (3 instancje typu `m4.xlarge`).\n",
    "\n",
    "![emr_1](EMR_1.png)\n",
    "\n",
    "#### Druga konfiguracja\n",
    "\n",
    "Druga konfiguracja to **6 x 2 core'y** (6 instancji typu `m4.large`).\n",
    "\n",
    "![emr_2](EMR_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc37361d",
   "metadata": {},
   "source": [
    "## Wyniki\n",
    "\n",
    "### Plik CSV\n",
    "\n",
    "Dane z poszczególnych plików time przeanalizowano i dodano do pliku `result.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b2ab7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nCores</th>\n",
       "      <th>confId</th>\n",
       "      <th>dataSize</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>466.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nCores  confId  dataSize    time\n",
       "0       1       0         1   90.68\n",
       "1       1       0         1   89.56\n",
       "2       1       0         1   89.83\n",
       "3       1       0         1   89.96\n",
       "4       1       0         5  466.19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = pd.read_csv(\"result.csv\")\n",
    "results.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c274c7cc",
   "metadata": {},
   "source": [
    "Dane następnie zgrupowano wg typu konfiguracji (`confId`) oraz wielkości danych (`time`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e161ffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nCores</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confId</th>\n",
       "      <th>dataSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>90.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>467.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>953.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>228.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>225.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nCores        time\n",
       "confId dataSize                    \n",
       "0      1            1.0   90.007500\n",
       "       5            1.0  467.306667\n",
       "       10           1.0  953.816667\n",
       "1      1            3.0  228.810000\n",
       "2      1            6.0  225.450000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res = results.groupby(['confId', 'dataSize'])\n",
    "mean_res = grouped_res.mean()\n",
    "\n",
    "mean_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb91d232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nCores</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confId</th>\n",
       "      <th>dataSize</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.664702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.075992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nCores      time\n",
       "confId dataSize                  \n",
       "0      1            0.0  0.478287\n",
       "       5            0.0  1.664702\n",
       "       10           0.0  9.075992\n",
       "1      1            NaN       NaN\n",
       "2      1            NaN       NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_res = grouped_res.std()\n",
    "std_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c20b770",
   "metadata": {},
   "source": [
    "Następnie policzono speedup w zależności od użytych core'ów dla wszystkich trzech konfiguracji. Jako wartość bazowa (w mianowniku) posłużył *czas wykonania algorytmu sekwencyjnego na ec2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ceceeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953.8166666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wyiczenie speedupu\n",
    "\n",
    "s1 = mean_res.values[0][1]\n",
    "s5 = mean_res.values[1][1]\n",
    "s10 = mean_res.values[2][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodanie kolumny ze speedupem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68b81201",
   "metadata": {},
   "source": [
    "### Wykresy\n",
    "\n",
    "#### W zależności od wielkości danych\n",
    "\n",
    "# wykres dla 1 Gb\n",
    "\n",
    "# wykres dla 5 GB\n",
    "\n",
    "# wykres dla 10 GB\n",
    "\n",
    "### W zależności od konfiguracji\n",
    "\n",
    "#### Konfiguracja sekwencyjna\n",
    "\n",
    "#### Konfiguracja równoległa\n",
    "\n",
    "### Komentarz\n",
    "\n",
    "COST wyszedł na mocną niekorzyść. EC2 poradziło sobie zdecydowanie lepiej. Spowodowane najprawdopdobniej dodatkowym nakładem na synchronizację danych. Można jedynie zauważyć, że confi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
